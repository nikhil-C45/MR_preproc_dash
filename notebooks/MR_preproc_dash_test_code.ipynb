{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code and scratch space for MR preproc dashboard \n",
    "\n",
    "1. Use pickle to load subject info and expected preproc steps\n",
    "2. Check directories to see output files \n",
    "3. Check logs to find out issues \n",
    "\n",
    "**Expected use case:** \n",
    "    Run this script after preprocessing is complete to provide info on each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "proj_dir = '/Users/nikhil/projects/MR_preproc_dash/'\n",
    "data_dir = proj_dir + 'data/'\n",
    "\n",
    "preproc_pipeline_dir = '/Users/nikhil/code/git_repos/nist_mni_pipelines/'\n",
    "if preproc_pipeline_dir not in sys.path:\n",
    "    sys.path.append(preproc_pipeline_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: read the pickle to get subject specific parameters and preproc stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>subject_dir</th>\n",
       "      <th>tp_idx</th>\n",
       "      <th>denoise</th>\n",
       "      <th>mask_N3</th>\n",
       "      <th>advanced_N4</th>\n",
       "      <th>mri3T</th>\n",
       "      <th>model_name</th>\n",
       "      <th>beast_dir</th>\n",
       "      <th>run_skull_registration</th>\n",
       "      <th>...</th>\n",
       "      <th>nsstx</th>\n",
       "      <th>clp</th>\n",
       "      <th>clp2</th>\n",
       "      <th>stx</th>\n",
       "      <th>stx2</th>\n",
       "      <th>vbm</th>\n",
       "      <th>cls</th>\n",
       "      <th>add</th>\n",
       "      <th>vol</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>052_S_4807</td>\n",
       "      <td>/data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/</td>\n",
       "      <td>20121019</td>\n",
       "      <td>expected</td>\n",
       "      <td>na</td>\n",
       "      <td>expected</td>\n",
       "      <td>expected</td>\n",
       "      <td>model_t1w</td>\n",
       "      <td>/ipl/quarantine/models/beast</td>\n",
       "      <td>na</td>\n",
       "      <td>...</td>\n",
       "      <td>expected</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>dir_missing</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>052_S_4807</td>\n",
       "      <td>/data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/</td>\n",
       "      <td>20120727</td>\n",
       "      <td>expected</td>\n",
       "      <td>na</td>\n",
       "      <td>expected</td>\n",
       "      <td>expected</td>\n",
       "      <td>model_t1w</td>\n",
       "      <td>/ipl/quarantine/models/beast</td>\n",
       "      <td>na</td>\n",
       "      <td>...</td>\n",
       "      <td>expected</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "      <td>timepoint_missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>052_S_4807</td>\n",
       "      <td>/data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/</td>\n",
       "      <td>20130215</td>\n",
       "      <td>expected</td>\n",
       "      <td>na</td>\n",
       "      <td>expected</td>\n",
       "      <td>expected</td>\n",
       "      <td>model_t1w</td>\n",
       "      <td>/ipl/quarantine/models/beast</td>\n",
       "      <td>na</td>\n",
       "      <td>...</td>\n",
       "      <td>expected</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>dir_missing</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>052_S_4807</td>\n",
       "      <td>/data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/</td>\n",
       "      <td>20150804</td>\n",
       "      <td>expected</td>\n",
       "      <td>na</td>\n",
       "      <td>expected</td>\n",
       "      <td>expected</td>\n",
       "      <td>model_t1w</td>\n",
       "      <td>/ipl/quarantine/models/beast</td>\n",
       "      <td>na</td>\n",
       "      <td>...</td>\n",
       "      <td>expected</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>dir_missing</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>dir_missing</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>052_S_4807</td>\n",
       "      <td>/data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/</td>\n",
       "      <td>20140807</td>\n",
       "      <td>expected</td>\n",
       "      <td>na</td>\n",
       "      <td>expected</td>\n",
       "      <td>expected</td>\n",
       "      <td>model_t1w</td>\n",
       "      <td>/ipl/quarantine/models/beast</td>\n",
       "      <td>na</td>\n",
       "      <td>...</td>\n",
       "      <td>expected</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>dir_missing</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>052_S_4807</td>\n",
       "      <td>/data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/</td>\n",
       "      <td>20130813</td>\n",
       "      <td>expected</td>\n",
       "      <td>na</td>\n",
       "      <td>expected</td>\n",
       "      <td>expected</td>\n",
       "      <td>model_t1w</td>\n",
       "      <td>/ipl/quarantine/models/beast</td>\n",
       "      <td>na</td>\n",
       "      <td>...</td>\n",
       "      <td>expected</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>file_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>file_missing</td>\n",
       "      <td>dir_missing</td>\n",
       "      <td>dir_exists</td>\n",
       "      <td>dir_exists</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_idx                                        subject_dir    tp_idx  \\\n",
       "0  052_S_4807  /data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/  20121019   \n",
       "1  052_S_4807  /data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/  20120727   \n",
       "2  052_S_4807  /data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/  20130215   \n",
       "3  052_S_4807  /data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/  20150804   \n",
       "4  052_S_4807  /data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/  20140807   \n",
       "5  052_S_4807  /data/ipl/scratch15/Mahsa/ADNI/LP/3T//052_S_4807/  20130813   \n",
       "\n",
       "    denoise mask_N3 advanced_N4     mri3T model_name  \\\n",
       "0  expected      na    expected  expected  model_t1w   \n",
       "1  expected      na    expected  expected  model_t1w   \n",
       "2  expected      na    expected  expected  model_t1w   \n",
       "3  expected      na    expected  expected  model_t1w   \n",
       "4  expected      na    expected  expected  model_t1w   \n",
       "5  expected      na    expected  expected  model_t1w   \n",
       "\n",
       "                      beast_dir run_skull_registration        ...          \\\n",
       "0  /ipl/quarantine/models/beast                     na        ...           \n",
       "1  /ipl/quarantine/models/beast                     na        ...           \n",
       "2  /ipl/quarantine/models/beast                     na        ...           \n",
       "3  /ipl/quarantine/models/beast                     na        ...           \n",
       "4  /ipl/quarantine/models/beast                     na        ...           \n",
       "5  /ipl/quarantine/models/beast                     na        ...           \n",
       "\n",
       "      nsstx                clp               clp2                stx  \\\n",
       "0  expected        file_exists        file_exists        file_exists   \n",
       "1  expected  timepoint_missing  timepoint_missing  timepoint_missing   \n",
       "2  expected        file_exists        file_exists        file_exists   \n",
       "3  expected       file_missing        file_exists       file_missing   \n",
       "4  expected        file_exists        file_exists        file_exists   \n",
       "5  expected        file_exists        file_exists        file_exists   \n",
       "\n",
       "                stx2                vbm                cls                add  \\\n",
       "0        file_exists         dir_exists       file_missing        dir_missing   \n",
       "1  timepoint_missing  timepoint_missing  timepoint_missing  timepoint_missing   \n",
       "2        file_exists         dir_exists       file_missing        dir_missing   \n",
       "3        file_exists        dir_missing       file_missing        dir_missing   \n",
       "4        file_exists         dir_exists       file_missing        dir_missing   \n",
       "5        file_exists         dir_exists       file_missing        dir_missing   \n",
       "\n",
       "                 vol                lng  \n",
       "0         dir_exists         dir_exists  \n",
       "1  timepoint_missing  timepoint_missing  \n",
       "2         dir_exists         dir_exists  \n",
       "3         dir_exists         dir_exists  \n",
       "4         dir_exists         dir_exists  \n",
       "5         dir_exists         dir_exists  \n",
       "\n",
       "[6 rows x 28 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dirs = ['clp','clp2','stx','stx2','vbm','cls','add','vol','lng']\n",
    "task_file_names_dict = {}\n",
    "task_file_names_dict['clp'] = ['clp','den','nuc']\n",
    "task_file_names_dict['clp2'] = ['clp2']\n",
    "task_file_names_dict['cls'] = ['csl','lob']\n",
    "task_file_names_dict['stx'] = ['stx','nsstx']\n",
    "task_file_names_dict['stx2'] = ['stx2']\n",
    "\n",
    "pipeline_data_pickle = pd.read_pickle(data_dir + 'logs/long_pipeline_052_S_4807.pickle')\n",
    "\n",
    "df = parse_pickle(pipeline_data_pickle,output_dirs)\n",
    "df, missing_tp, missing_dir = check_output_dirs(df,output_dirs)\n",
    "df, missing_file = check_output_files(df,task_file_names_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: 052_S_4807\n",
      "missing timepoints: ['20120727']\n",
      "\n",
      "missing dir: ['20121019/add', '20130215/add', '20150804/stx', '20150804/vbm', '20150804/cls', '20150804/add', '20140807/add', '20130813/add']\n",
      "\n",
      "missing files: ['20121019/cls/csl_052_S_4807_20121019_t1.mnc', '20121019/cls/lob_052_S_4807_20121019_t1.mnc', '20130215/cls/csl_052_S_4807_20130215_t1.mnc', '20130215/cls/lob_052_S_4807_20130215_t1.mnc', '20150804/clp/clp_052_S_4807_20150804_t1.mnc', '20150804/clp/nuc_052_S_4807_20150804_t1.mnc', '20150804/cls/csl_052_S_4807_20150804_t1.mnc', '20150804/cls/lob_052_S_4807_20150804_t1.mnc', '20150804/stx/stx_052_S_4807_20150804_t1.mnc', '20150804/stx/nsstx_052_S_4807_20150804_t1.mnc', '20140807/cls/csl_052_S_4807_20140807_t1.mnc', '20140807/cls/lob_052_S_4807_20140807_t1.mnc', '20130813/cls/csl_052_S_4807_20130813_t1.mnc', '20130813/cls/lob_052_S_4807_20130813_t1.mnc']\n"
     ]
    }
   ],
   "source": [
    "print('subject: {}'.format(df['subject_idx'].values[0]))\n",
    "print('missing timepoints: {}'.format(missing_tp))\n",
    "print('')\n",
    "print('missing dir: {}'.format(missing_dir)) \n",
    "print('')\n",
    "print('missing files: {}'.format(missing_file)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse subject -> timepoint info\n",
    "def parse_pickle(pkl, output_dirs):\n",
    "    # the task columns represent the current state of the task (na/expected/completed/failed)\n",
    "    info_cols = ['subject_idx','subject_dir','tp_idx','denoise','mask_N3','advanced_N4','mri3T','model_name',\n",
    "                'beast_dir','run_skull_registration','beastresolution','number_of_timepoints','pipeline_version',\n",
    "                'donl','dolngcls','nuc','den','lob','nsstx']\n",
    "    \n",
    "    subject_df = pd.DataFrame(columns=info_cols+output_dirs)\n",
    "    number_of_tp = len(pkl)\n",
    "    for t, tp in enumerate(pkl.keys()):\n",
    "        subject_df.loc[t,'subject_idx'] = pkl.id\n",
    "        subject_df.loc[t,'subject_dir'] = pkl.patientdir \n",
    "        subject_df.loc[t,'tp_idx'] = tp\n",
    "        subject_df.loc[t,'denoise'] = pkl.denoise\n",
    "        subject_df.loc[t,'mask_N3'] = pkl.mask_n3\n",
    "        subject_df.loc[t,'advanced_N4'] = pkl.n4\n",
    "        subject_df.loc[t,'donl'] = pkl.donl\n",
    "        subject_df.loc[t,'dolngcls'] = pkl.dolngcls\n",
    "        subject_df.loc[t,'mri3T'] = pkl.mri3T\n",
    "        subject_df.loc[t,'beast_dir'] = pkl.beastdir\n",
    "        subject_df.loc[t,'model_name'] = pkl.modelname\n",
    "        subject_df.loc[t,'run_skull_registration'] = pkl.skullreg\n",
    "        subject_df.loc[t,'beastresolution'] = pkl.beastresolution\n",
    "        subject_df.loc[t,'number_of_timepoints'] = number_of_tp\n",
    "        subject_df.loc[t,'pipeline_version'] = pkl.pipeline_version\n",
    "        \n",
    "        #Commonly done preproc tasks\n",
    "        subject_df.loc[t,'nuc'] = True\n",
    "        subject_df.loc[t,'den'] = True\n",
    "        subject_df.loc[t,'clp'] = True\n",
    "        subject_df.loc[t,'clp2'] = True\n",
    "        subject_df.loc[t,'stx'] = True\n",
    "        subject_df.loc[t,'nsstx'] = True\n",
    "        subject_df.loc[t,'stx2'] = True\n",
    "        subject_df.loc[t,'vbm'] = True\n",
    "        subject_df.loc[t,'cls'] = True\n",
    "        subject_df.loc[t,'lob'] = True\n",
    "        subject_df.loc[t,'add'] = True\n",
    "        subject_df.loc[t,'vol'] = True\n",
    "        subject_df.loc[t,'lng'] = True\n",
    "        \n",
    "        subject_df = subject_df.replace({True:'expected',False:'na'})\n",
    "        \n",
    "    return subject_df\n",
    "    \n",
    "\n",
    "# Check diretory tree created at the beginning of the pipeline (catch permission failures)\n",
    "def check_output_dirs(subject_df,output_dirs):\n",
    "    #subject_dir = subject_df['subject_dir'].values[0] # on BIC system\n",
    "    subject_dir = data_dir + '052_S_4807/' #for local tests \n",
    "    \n",
    "    missing_tp = []\n",
    "    missing_dir = []\n",
    "    for tp in subject_df['tp_idx'].values:\n",
    "        if os.path.isdir(subject_dir+tp):\n",
    "            for out_dir in output_dirs:\n",
    "                if os.path.isdir(subject_dir+tp+'/'+out_dir):\n",
    "                    subject_df.loc[subject_df['tp_idx']==tp,out_dir] = 'dir_exists'\n",
    "                else:\n",
    "                    subject_df.loc[subject_df['tp_idx']==tp,out_dir] = 'dir_missing'\n",
    "                    missing_dir.append(tp + '/' + out_dir)\n",
    "        else:\n",
    "            missing_tp.append(tp)\n",
    "            subject_df.loc[subject_df['tp_idx']==tp,output_dirs] = 'timepoint_missing'\n",
    "    \n",
    "    return subject_df, missing_tp, missing_dir\n",
    "\n",
    "# Check output files creates at each stage of the pipeline (catch processing errors)\n",
    "def check_output_files(subject_df,task_file_names_dict):\n",
    "    missing_file = []\n",
    "    #subject_dir = subject_df['subject_dir'].values[0] # on BIC system\n",
    "    subject_dir = data_dir + '052_S_4807/' #for local tests \n",
    "    subject_idx = subject_df['subject_idx'].values[0]\n",
    "    for tp in subject_df['tp_idx'].values:    \n",
    "        if os.path.isdir(subject_dir+tp):\n",
    "            for out_dir in task_file_names_dict.keys():\n",
    "                expected_files = task_file_names_dict[out_dir]\n",
    "                for f in expected_files:\n",
    "                    file_name = '{}_{}_{}_t1.mnc'.format(f,subject_idx,tp) \n",
    "                    if os.path.isfile(subject_dir+tp+'/'+out_dir+'/'+file_name):\n",
    "                        subject_df.loc[subject_df['tp_idx']==tp,out_dir] = 'file_exists'\n",
    "                    else:\n",
    "                        subject_df.loc[subject_df['tp_idx']==tp,out_dir] = 'file_missing'\n",
    "                        missing_file.append(tp + '/' + out_dir + '/' + file_name) \n",
    "    return subject_df, missing_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
